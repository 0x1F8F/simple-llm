{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0bdbd88-c162-4ee1-9df9-0647e86bc4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sllm2\n",
    "import torch\n",
    "from torch import nn\n",
    "from plotly import express as ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dab05d4-05a0-4b19-9788-ecf96cf33027",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../simple-llm2/cache.txt\") as f:\n",
    "    db = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6992b1c9-abc1-4dd6-b3e1-e21b34ca3ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(db))\n",
    "vocab_size = vsz = len(vocab)\n",
    "tokenizer = sllm2.tokenizer.Tokenizer()\n",
    "tokenizer.train(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "941566eb-8170-4385-a6cb-e2a03c01f188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n', ' ', '\"', '&']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edb69bd4-9944-4ef3-9858-627eb5de8ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10000]), torch.int64, device(type='cpu'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor(tokenizer.encode(db))\n",
    "data.shape , data.dtype , data.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2126820-bacd-4f9b-a88d-e75f5e2ac1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int (len(db) * 0.9)\n",
    "train = data[:split]\n",
    "test = data[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2631abb5-bef0-444b-8864-d126206c6536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"s throughout the world.\\nIn 1988, Irvine became the first non-American president of World Vision International.\\nJim Daly.\\ncame from Woodside army camp where he was a YMCA army officer.\\nAfter his Army service he joined the Adelaide Y as Extension Secretary under Irvine having responsibility for developing boards, programmes and ensuring the viability of Walkerville, Northern Districts (Kilburn), West Croydon and Elizabeth Branches.\\nHe was a senior leader at the first Kangaroo Island Camp and many others in preceding years.\\nThey were initially organised initially by Don McCallum, Physical Education Director and in following years by Ross Baxter Glen Powell, Gary Kelly, Dean Manning, Dave Badger, Tim Looker.\\nThe Kangaroo Island Camps ran for nearly 40 years.\\nDaly's particular interest was in Adventure Camping.\\nHe personally led groups of senior leaders on Outward Bound-type expeditions to New Zealand, Tasmania (Cradle Mountain Track, Flinders Ranges and the Grampians).\\nDaly went on become \""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(tokenizer.decode(test.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1b6c50c7-a006-405b-94b9-fc5d4d5d7dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ability of Walkervil"
     ]
    }
   ],
   "source": [
    "def get_data(batch_size , window_size = 20 , val = False):\n",
    "    data = test if val else train\n",
    "    random_pos = torch.randint(len(data)-window_size, (window_size,))\n",
    "    x = torch.stack([ data[ i  :i+window_size  ] for i in random_pos ])\n",
    "    y = torch.stack([ data[ i+1:i+window_size+1] for i in random_pos ])\n",
    "    return x,y\n",
    "\n",
    "x,y = get_data(batch_size=4, val=True)\n",
    "print(\"\\r\"+\"\".join(tokenizer.decode(x[0].tolist())), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e9ba66b-ad26-46a2-90ea-591accef587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ModelArg:\n",
    "    vocab_size: int = -1\n",
    "    emb_size: int = 32\n",
    "    head_size: int = 32\n",
    "    window_size: int = 20\n",
    "    lr: float  = 1e-3\n",
    "    batch_size: int = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5ec56ad1-aac2-443a-9549-54bec6ffeb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = ModelArg(\n",
    "    vocab_size = vocab_size,\n",
    "    emb_size = vocab_size,\n",
    "    batch_size= 4,\n",
    "    head_size= -1,\n",
    "    window_size=20\n",
    ")\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self , arg: ModelArg):\n",
    "        super().__init__()\n",
    "        self.arg = arg\n",
    "        self.embedding = nn.Embedding(arg.vocab_size , arg.emb_size) # -> (batch , token , emb)\n",
    "    \n",
    "    def forward(self,x : torch.Tensor) -> torch.Tensor:\n",
    "        b , t = x.shape\n",
    "        logits = self.embedding(x)\n",
    "        return logits\n",
    "\n",
    "net = Transformer(model_args)\n",
    "x,y = get_data(model_args.batch_size, model_args.window_size)\n",
    "logits = net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "4ecd4336-8e85-4ae1-b7b4-94d48c14b5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 20, 75])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a7ba5fb3-a969-4ff9-b7c4-cd6425ae960a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[56],\n",
       "        [45],\n",
       "        [53],\n",
       "        [25],\n",
       "        [53],\n",
       "        [44],\n",
       "        [ 0],\n",
       "        [ 5],\n",
       "        [ 4],\n",
       "        [26],\n",
       "        [29],\n",
       "        [ 5],\n",
       "        [47],\n",
       "        [38],\n",
       "        [24],\n",
       "        [11],\n",
       "        [19],\n",
       "        [42],\n",
       "        [27],\n",
       "        [23]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = nn.functional.softmax(logits , dim=-1)\n",
    "torch.multinomial(l[:,-1,:], 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
